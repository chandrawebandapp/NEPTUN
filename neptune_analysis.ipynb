{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: bhayera\n",
      "Romanized variations ['bhhairaa', 'bhayera', 'bhaeraa', 'bhayraa', 'bhhaira', 'bhayra', 'bhaaera', 'bhaaeraa', 'bhaera', 'bhaayraa', 'bhaayra', 'bhhaera']\n",
      "Devanagari variations: ['рднреНрд╣реИрд░рд╛', 'рднрдпреЗрд░', 'рднрдПрд░рд╛', 'рднрдпреНрд░рд╛', 'рднреНрд╣реИрд░', 'рднрдпреНрд░', 'рднрд╛рдПрд░', 'рднрд╛рдПрд░рд╛', 'рднрдПрд░', 'рднрд╛рдпреНрд░рд╛', 'рднрд╛рдпреНрд░', 'рднреНрд╣рдПрд░']\n"
     ]
    }
   ],
   "source": [
    "from indic_transliteration import sanscript\n",
    "from indic_transliteration.sanscript import transliterate\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "# Define phonetic variations\n",
    "variation_map = {\n",
    "    \"aa\": [\"a\", \"aa\"],\n",
    "    \"a\": [\"a\", \"aa\"],\n",
    "    \"ah\": [\"a\", \"ah\", \"aa\"],\n",
    "    \"w\": [\"a\", \"w\"],\n",
    "    \"e\": [\"e\", \"ee\"],\n",
    "    \"ee\": [\"e\", \"ee\"],\n",
    "    \"i\": [\"i\", \"ii\"],\n",
    "    \"o\": [\"o\"],\n",
    "    \"oo\": [\"u\", \"uu\", \"oo\"],\n",
    "    \"u\": [\"u\", \"uu\"],\n",
    "    \"uu\": [\"u\", \"uu\"],\n",
    "    \"ae\": [\"ai\"],\n",
    "    \"ye\": [\"e\", \"y\"],\n",
    "    \"s\": [\"sh\", \"shh\"],\n",
    "    \"sh\": [\"s\", \"shh\"],\n",
    "    \"shh\": [\"s\", \"sh\"]\n",
    "}\n",
    "\n",
    "# Additional consonant variations\n",
    "consonant_map = {\n",
    "    \"chh\": [\"x\", \"ch\", \"xw\", \"xah\"],\n",
    "    \"e\": [\"ye\", \"ya\"],\n",
    "    \"pha\": [\"fa\"],\n",
    "    \"a\": [\"w\",],\n",
    "    'T': [\"t\", \"tt\"],\n",
    "    'Th': [\"Th\"],\n",
    "    'D': [\"d\"],\n",
    "    'Dh': [\"dh\"],\n",
    "    'v': ['b', 'bh'],\n",
    "    # 'b': ['v'],\n",
    "    'bh': ['v']\n",
    "}\n",
    "\n",
    "last_word_check_list = ['w','ah']\n",
    "\n",
    "def handle_repeated_chars(roman_word):\n",
    "        \"\"\"Reduce long repeated vowels (e.g., 'aaaa' тЖТ 'aa').\"\"\"\n",
    "        optimized_word = []\n",
    "        i = 0\n",
    "        while i < len(roman_word):\n",
    "            match = re.match(r\"([a-zA-Z])\\1{2,}\", roman_word[i:])\n",
    "            if match:\n",
    "                char = match.group(1)\n",
    "                optimized_word.append(char)  # Keep one repetition (aa, ee, etc.)\n",
    "                i += len(match.group(0))\n",
    "            else:\n",
    "                optimized_word.append(roman_word[i])\n",
    "                i += 1\n",
    "        return \"\".join(optimized_word)\n",
    "\n",
    "\n",
    "\n",
    "def generate_variations(word):\n",
    "    normalize_word = handle_repeated_chars(word)\n",
    "\n",
    "    new_words = [normalize_word]\n",
    "\n",
    "    for key, variations in consonant_map.items():\n",
    "        for variation in variations:\n",
    "            if variation in normalize_word and (key not in normalize_word or key in [\"e\"]):\n",
    "                normalize_word = normalize_word.replace(variation, key)\n",
    "    new_words.append(normalize_word)\n",
    "    # print('new_words', new_words)\n",
    "\n",
    "    new_variations = list(new_words)\n",
    "    # print('new_variations', new_variations)\n",
    "    for roman_word in new_words:\n",
    "        tokens = []\n",
    "        i = 0\n",
    "        while i < len(roman_word):\n",
    "            # print('roman_word', roman_word)\n",
    "            if i + 1 < len(roman_word) and roman_word[i:i+2] in variation_map:\n",
    "                if (i + 2 < len(roman_word)) and roman_word[i:i+2] in last_word_check_list:\n",
    "                    if roman_word[i] in variation_map:\n",
    "                        tokens.append(variation_map[roman_word[i]])\n",
    "                    else:\n",
    "                        tokens.append([roman_word[i]])\n",
    "                    i += 1\n",
    "                else:\n",
    "                    tokens.append(variation_map[roman_word[i:i+2]])\n",
    "                    i += 2\n",
    "            elif roman_word[i] in variation_map:\n",
    "                if (i + 2 < len(roman_word)) and roman_word[i] in last_word_check_list:\n",
    "                    tokens.append([roman_word[i]])\n",
    "                else:\n",
    "                    tokens.append(variation_map[roman_word[i]])\n",
    "                i += 1\n",
    "            else:\n",
    "                tokens.append([roman_word[i]])\n",
    "                i += 1\n",
    "            # print('tokens', tokens)\n",
    "\n",
    "        variations = [\"\".join(variant) for variant in itertools.product(*tokens)]\n",
    "        new_variations.extend(variations)\n",
    "\n",
    "    return set(new_variations)\n",
    "\n",
    "# Example usage\n",
    "\n",
    "def generate_devnagri_variations(variant):\n",
    "    latin_variations = generate_variations(variant)\n",
    "    # print('latin_variations', latin_variations)\n",
    "    devanagari_variations = []\n",
    "    print('Romanized variations', list(latin_variations))\n",
    "    for variant in latin_variations:\n",
    "        nepali = transliterate(variant, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
    "        devanagari_variations.append(nepali)\n",
    "    return devanagari_variations\n",
    "\n",
    "\n",
    "variant = \"bhayera\"\n",
    "# variant = \"vahirw\"\n",
    "print('word:', variant)\n",
    "devanagari_variations = generate_devnagri_variations(variant)\n",
    "print('Devanagari variations:', devanagari_variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "PICKLE_FILE = \"dictionary/word_count.pkl\"  # Path to the saved pickle file\n",
    "\n",
    "def load_saved_word_count():\n",
    "    \"\"\"Load and return the word frequency dictionary from the pickle file.\"\"\"\n",
    "    if os.path.exists(PICKLE_FILE):\n",
    "        with open(PICKLE_FILE, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    else:\n",
    "        print(\"No saved word count dictionary found.\")\n",
    "        return {}  # Return an empty dictionary if the file doesn't exist\n",
    "\n",
    "# Usage\n",
    "saved_word_count = load_saved_word_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240683"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(saved_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def rank_variants_by_similarity(variants, nepali_dictionary):\n",
    "    \"\"\"\n",
    "    Rank the generated variants by their similarity to words in the Nepali dictionary using TF-IDF.\n",
    "\n",
    "    :param variants: List of transliterated Nepali variants.\n",
    "    :param nepali_dictionary: List of words in the Nepali dictionary.\n",
    "    :return: List of variants ordered by similarity along with matched dictionary word and similarity score.\n",
    "    \"\"\"\n",
    "    # Ensure both dictionary and variants are lists\n",
    "    nepali_dictionary = list(nepali_dictionary)\n",
    "\n",
    "    # Combine variants and dictionary into a single corpus\n",
    "    corpus = nepali_dictionary + variants\n",
    "\n",
    "    # Compute TF-IDF vectors\n",
    "    # vectorizer = TfidfVectorizer(analyzer='char')\n",
    "    vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(2, 4))\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    # Calculate similarity of each variant to the dictionary words\n",
    "    dictionary_size = len(nepali_dictionary)\n",
    "    variant_vectors = tfidf_matrix[dictionary_size:]\n",
    "    dictionary_vectors = tfidf_matrix[:dictionary_size]\n",
    "\n",
    "    similarities = cosine_similarity(variant_vectors, dictionary_vectors)\n",
    "\n",
    "    # Rank variants by maximum similarity to any dictionary word\n",
    "    ranked_variants = []\n",
    "    for i, variant in enumerate(variants):\n",
    "        max_sim_index = similarities[i].argmax()\n",
    "        matched_word = nepali_dictionary[max_sim_index]\n",
    "        similarity_score = similarities[i, max_sim_index]\n",
    "        ranked_variants.append((variant, matched_word, similarity_score))\n",
    "\n",
    "    ranked_variants.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    return ranked_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Romanized variations ['bhhairaa', 'bhayera', 'bhaeraa', 'bhayraa', 'bhhaira', 'bhayra', 'bhaaera', 'bhaaeraa', 'bhaera', 'bhaayraa', 'bhaayra', 'bhhaera']\n",
      "Devanagari variations: ['рднреНрд╣реИрд░рд╛', 'рднрдпреЗрд░', 'рднрдПрд░рд╛', 'рднрдпреНрд░рд╛', 'рднреНрд╣реИрд░', 'рднрдпреНрд░', 'рднрд╛рдПрд░', 'рднрд╛рдПрд░рд╛', 'рднрдПрд░', 'рднрд╛рдпреНрд░рд╛', 'рднрд╛рдпреНрд░', 'рднреНрд╣рдПрд░']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_devnagri_variations(variant):\n",
    "    latin_variations = generate_variations(variant)\n",
    "    devanagari_variations = []\n",
    "    print('Romanized variations', list(latin_variations))\n",
    "    for variant in latin_variations:\n",
    "        nepali = transliterate(variant, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
    "        devanagari_variations.append(nepali)\n",
    "    return devanagari_variations\n",
    "\n",
    "\n",
    "\n",
    "variant = \"bhayera\" # \"choto\"\n",
    "devanagari_variations = generate_devnagri_variations(variant)\n",
    "print('Devanagari variations:', devanagari_variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Matched Words:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('рднрдпреЗрд░', 'рднрдпреЗрд░', np.float64(1.0000000000000002)),\n",
       " ('рднрдПрд░', 'рднрдПрд░', np.float64(1.0)),\n",
       " ('рднрдпреНрд░', 'рднрдпреНрд░рд░', np.float64(0.8047247769238031)),\n",
       " ('рднрд╛рдПрд░', 'рдирд┐рднрд╛рдПрд░', np.float64(0.7061244569651446)),\n",
       " ('рднрдпреНрд░рд╛', 'рднрдпреНрд░рд░', np.float64(0.7044708057411735)),\n",
       " ('рднрд╛рдпреНрд░', 'рдорд╛рдпреНрд░', np.float64(0.6456314729709742)),\n",
       " ('рднрдПрд░рд╛', 'рднрдПрд░', np.float64(0.6434916170887707)),\n",
       " ('рднрд╛рдпреНрд░рд╛', 'рдорд╛рдпреНрд░', np.float64(0.5848289707228022)),\n",
       " ('рднрд╛рдПрд░рд╛', 'рдирд┐рднрд╛рдПрд░', np.float64(0.5561902315551083)),\n",
       " ('рднреНрд╣реИрд░рд╛', 'рд╣реИрд░рд╛рди', np.float64(0.5516259195722237)),\n",
       " ('рднреНрд╣реИрд░', 'рд╣реИрд░реА', np.float64(0.36008991294924636)),\n",
       " ('рднреНрд╣рдПрд░', 'рд░рд╣рдП', np.float64(0.23631770944209657))]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEPALI_DICTIONARY= saved_word_count\n",
    "top_matched_words = rank_variants_by_similarity(devanagari_variations, NEPALI_DICTIONARY)\n",
    "\n",
    "print(\"\\nTop 5 Matched Words:\")\n",
    "top_matched_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "from metaphone import doublemetaphone\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"files/words_devnagri_root.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Devanagari</th>\n",
       "      <th>Root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xata</td>\n",
       "      <td>рдЫрдЯ</td>\n",
       "      <td>рдЫрдЯ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xatw</td>\n",
       "      <td>рдЫрдЯ</td>\n",
       "      <td>рдЫрдЯ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xodyo</td>\n",
       "      <td>рдЫреЛрдбреНрдпреЛ</td>\n",
       "      <td>рдЫреЛрдбреНрдпреЛ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xoto</td>\n",
       "      <td>рдЫреЛрдЯреЛ</td>\n",
       "      <td>рдЫреЛрдЯреЛ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sidhai</td>\n",
       "      <td>рд╕рд┐рдзреИ</td>\n",
       "      <td>рд╕рд┐рдзрд╛</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Words Devanagari     Root\n",
       "0    xata         рдЫрдЯ       рдЫрдЯ\n",
       "1    xatw         рдЫрдЯ       рдЫрдЯ\n",
       "2   xodyo     рдЫреЛрдбреНрдпреЛ   рдЫреЛрдбреНрдпреЛ\n",
       "3    xoto       рдЫреЛрдЯреЛ     рдЫреЛрдЯреЛ\n",
       "4  sidhai       рд╕рд┐рдзреИ     рд╕рд┐рдзрд╛"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('Devanagari')['Words'].apply(list).reset_index()\n",
    "\n",
    "# Filter to only include entries with more than one word\n",
    "filtered = grouped[grouped['Words'].apply(len) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Devanagari</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>рдкрд░рд┐рдпреЛ</td>\n",
       "      <td>[pariyo, pareyo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>рдкрд░реНрдпреЛ</td>\n",
       "      <td>[paryoo, paryo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>рдкреБрд░реИ</td>\n",
       "      <td>[paurai, purae]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>рднрдПрд░</td>\n",
       "      <td>[vayerw, vaera, vayeraw, bhaera]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>рднрдПрд░</td>\n",
       "      <td>[vayera, vayeraw, vayara, vayerw, bhayera]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>рд╕рд┐рдзреИ</td>\n",
       "      <td>[sidhai, siddai]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Devanagari                                       Words\n",
       "3       рдкрд░рд┐рдпреЛ                            [pariyo, pareyo]\n",
       "4       рдкрд░реНрдпреЛ                             [paryoo, paryo]\n",
       "5        рдкреБрд░реИ                             [paurai, purae]\n",
       "7         рднрдПрд░            [vayerw, vaera, vayeraw, bhaera]\n",
       "16        рднрдПрд░  [vayera, vayeraw, vayara, vayerw, bhayera]\n",
       "18       рд╕рд┐рдзреИ                            [sidhai, siddai]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "тЭМ Multiple mappings found: {('рдкрд╛рд░рд┐рдпреЛ',): 1, ('рдкрд╛рд░реАрдпреЛ',): 1}\n",
      "тЬЕ Keeping only the most frequent one: '('рдкрд╛рд░рд┐рдпреЛ',)' тАФ Adding 1\n",
      "тЭМ Multiple mappings found: {('рдкрд╛рд░реНрдпреБ',): 1, ('рдкрд░реНрдпреЛ',): 1}\n",
      "тЬЕ Keeping only the most frequent one: '('рдкрд╛рд░реНрдпреБ',)' тАФ Adding 1\n",
      "тЭМ Multiple mappings found: {('рдкреМрд░рд╛рдИ',): 1, ('рдкреБрд░реИ',): 1}\n",
      "тЬЕ Keeping only the most frequent one: '('рдкреМрд░рд╛рдИ',)' тАФ Adding 1\n",
      "тЭМ Multiple mappings found: {('рд╡рдпреЗрд░',): 1, ('рдмреИрд░рд╛',): 2, ('рднрдПрд░',): 1}\n",
      "тЬЕ Keeping only the most frequent one: '('рдмреИрд░рд╛',)' тАФ Adding 2\n",
      "тЭМ Multiple mappings found: {('рдмреИрд░рд╛',): 2, ('рд╡рд╛рдпрд░',): 1, ('рд╡рдпреЗрд░',): 1, ('рднрдпреЗрд░',): 1}\n",
      "тЬЕ Keeping only the most frequent one: '('рдмреИрд░рд╛',)' тАФ Adding 2\n",
      "тЭМ Multiple mappings found: {('рд╕рд┐рдзреИ',): 1, ('рд╕рд┐рджреНрджреИ',): 1}\n",
      "тЬЕ Keeping only the most frequent one: '('рд╕рд┐рдзреИ',)' тАФ Adding 1\n",
      "accurate: 8 total: 17 percent0.47058823529411764\n"
     ]
    }
   ],
   "source": [
    "# from collections import Counter\n",
    "# total = 0\n",
    "# accurate = 0\n",
    "# not_accurate = 0\n",
    "# NEPALI_DICTIONARY = saved_word_count\n",
    "\n",
    "# for nepali_word, variants in zip(filtered['Devanagari'], filtered['Words']):\n",
    "#     # print(\"nepali_word\", nepali_word, 'variants', variants)\n",
    "#     nepali_variations = []\n",
    "#     for variant in variants:\n",
    "#       total +=1\n",
    "#       latin_variations = generate_variations(variant)\n",
    "#       devanagari_variations = []\n",
    "#       for new_variant in latin_variations:\n",
    "#           nepali = transliterate(new_variant, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
    "#           devanagari_variations.append(nepali)\n",
    "#       top_matched_words = rank_variants_by_similarity(devanagari_variations, NEPALI_DICTIONARY)\n",
    "#       nepali = top_matched_words[0][0] if top_matched_words else None\n",
    "#       nepali_variations.append((nepali,))\n",
    "#     # Count occurrences of each mapped Nepali word\n",
    "#     counter = Counter(nepali_variations)\n",
    "#     most_common_word, count = counter.most_common(1)[0]\n",
    "\n",
    "#     if len(counter) == 1:\n",
    "#         print(f\"тЬЕ All variants map to the same Nepali word: '{most_common_word}' тАФ Adding {count}\")\n",
    "#         accurate += count\n",
    "#     else:\n",
    "#         print(f\"тЭМ Multiple mappings found: {dict(counter)}\")\n",
    "#         print(f\"тЬЕ Keeping only the most frequent one: '{most_common_word}' тАФ Adding {count}\")\n",
    "#         accurate += count\n",
    "# print(f'accurate: {accurate} total: {total} percent{accurate/total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ЁЯФБ Mismatch: Variant 'pariyo' тЖТ Mapped 'рдкрд╛рд░рд┐рдпреЛ', Expected ' рдкрд░рд┐рдпреЛ'\n",
      "ЁЯФБ Mismatch: Variant 'pareyo' тЖТ Mapped 'рдкрд╛рд░реАрдпреЛ', Expected ' рдкрд░рд┐рдпреЛ'\n",
      "ЁЯФБ Mismatch: Variant 'paryoo' тЖТ Mapped 'рдкрд╛рд░реНрдпреБ', Expected ' рдкрд░реНрдпреЛ'\n",
      "ЁЯФБ Mismatch: Variant 'paryo' тЖТ Mapped 'рдкрд░реНрдпреЛ', Expected ' рдкрд░реНрдпреЛ'\n",
      "ЁЯФБ Mismatch: Variant 'paurai' тЖТ Mapped 'рдкреМрд░рд╛рдИ', Expected ' рдкреБрд░реИ'\n",
      "ЁЯФБ Mismatch: Variant 'purae' тЖТ Mapped 'рдкреБрд░реИ', Expected ' рдкреБрд░реИ'\n",
      "ЁЯФБ Mismatch: Variant 'vayerw' тЖТ Mapped 'рд╡рдпреЗрд░', Expected ' рднрдПрд░'\n",
      "ЁЯФБ Mismatch: Variant 'vaera' тЖТ Mapped 'рдмреИрд░рд╛', Expected ' рднрдПрд░'\n",
      "ЁЯФБ Mismatch: Variant 'vayeraw' тЖТ Mapped 'рдмреИрд░рд╛', Expected ' рднрдПрд░'\n",
      "ЁЯФБ Mismatch: Variant 'bhaera' тЖТ Mapped 'рднрдПрд░', Expected ' рднрдПрд░'\n",
      "ЁЯФБ Mismatch: Variant 'vayera' тЖТ Mapped 'рдмреИрд░рд╛', Expected 'рднрдПрд░'\n",
      "ЁЯФБ Mismatch: Variant 'vayeraw' тЖТ Mapped 'рдмреИрд░рд╛', Expected 'рднрдПрд░'\n",
      "ЁЯФБ Mismatch: Variant 'vayara' тЖТ Mapped 'рд╡рд╛рдпрд░', Expected 'рднрдПрд░'\n",
      "ЁЯФБ Mismatch: Variant 'vayerw' тЖТ Mapped 'рд╡рдпреЗрд░', Expected 'рднрдПрд░'\n",
      "ЁЯФБ Mismatch: Variant 'bhayera' тЖТ Mapped 'рднрдпреЗрд░', Expected 'рднрдПрд░'\n",
      "ЁЯФБ Mismatch: Variant 'siddai' тЖТ Mapped 'рд╕рд┐рджреНрджреИ', Expected 'рд╕рд┐рдзреИ'\n",
      "accurate: 8, total: 17, percent: 0.47\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "total = 0\n",
    "accurate = 0\n",
    "not_accurate = 0\n",
    "NEPALI_DICTIONARY = saved_word_count\n",
    "\n",
    "for nepali_word, variants in zip(filtered['Devanagari'], filtered['Words']):\n",
    "    nepali_variations = []\n",
    "    for variant in variants:\n",
    "        total += 1\n",
    "        latin_variations = generate_variations(variant)\n",
    "        devanagari_variations = []\n",
    "        for new_variant in latin_variations:\n",
    "            nepali = transliterate(new_variant, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
    "            devanagari_variations.append(nepali)\n",
    "        top_matched_words = rank_variants_by_similarity(devanagari_variations, NEPALI_DICTIONARY)\n",
    "        nepali = top_matched_words[0][0] if top_matched_words else None\n",
    "        nepali_variations.append((nepali, variant))  # store variant too for debugging\n",
    "\n",
    "    # Find the most common mapped word\n",
    "    mapped_words_only = [x[0] for x in nepali_variations]\n",
    "    counter = Counter(mapped_words_only)\n",
    "    most_common_word, count = counter.most_common(1)[0]\n",
    "\n",
    "    # Now keep only those variants where mapped word == most_common_word\n",
    "    filtered_nepali_variations = [\n",
    "        (mapped_word, variant) for mapped_word, variant in nepali_variations if mapped_word == most_common_word\n",
    "    ]\n",
    "\n",
    "    if len(counter) == 1:\n",
    "        print(f\"тЬЕ All variants map to the same Nepali word: '{most_common_word}' тАФ Adding {count}\")\n",
    "        accurate += count\n",
    "    else:\n",
    "        print(f\"тЭМ Multiple mappings found: {dict(counter)}\")\n",
    "        print(f\"тЬЕ Keeping only the most frequent one: '{most_common_word}' тАФ Adding {count}\")\n",
    "        accurate += count\n",
    "\n",
    "    # Now check mismatches based on filtered mappings\n",
    "    for mapped_word, variant in nepali_variations:\n",
    "        if mapped_word != nepali_word:\n",
    "            print(f\"ЁЯФБ Mismatch: Variant '{variant}' тЖТ Mapped '{mapped_word}', Expected '{nepali_word}'\")\n",
    "            not_accurate += 1\n",
    "\n",
    "\n",
    "print(f'accurate: {accurate}, total: {total}, percent: {accurate / total:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "тЭМ Multiple mappings found: {'рд╕рд┐рдзреИ': 1, 'рд╕рд┐рджреНрджреИ': 1}\n",
      "тЬЕ Keeping only the most frequent one: 'рд╕рд┐рдзреИ' тАФ Adding 1\n",
      "ЁЯФБ Mismatch: Variant 'siddai' тЖТ Mapped 'рд╕рд┐рджреНрджреИ', Expected 'рд╕рд┐рдзреИ'\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

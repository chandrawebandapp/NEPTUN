{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: ramro\n",
      "Romanized variations ['ramro', 'raamro']\n",
      "Devanagari variations: ['रम्रो', 'राम्रो']\n"
     ]
    }
   ],
   "source": [
    "from indic_transliteration import sanscript\n",
    "from indic_transliteration.sanscript import transliterate\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "# Define phonetic variations\n",
    "variation_map = {\n",
    "    \"aa\": [\"a\", \"aa\"],\n",
    "    \"a\": [\"a\", \"aa\"],\n",
    "    \"ah\": [\"a\", \"ah\", \"aa\"],\n",
    "    \"w\": [\"a\", \"w\"],\n",
    "    \"e\": [\"e\", \"ee\"],\n",
    "    \"ee\": [\"e\", \"ee\"],\n",
    "    \"i\": [\"i\", \"ii\"],\n",
    "    \"o\": [\"o\"],\n",
    "    \"oo\": [\"u\", \"uu\", \"oo\"],\n",
    "    \"u\": [\"u\", \"uu\"],\n",
    "    \"uu\": [\"u\", \"uu\"],\n",
    "    \"ae\": [\"ai\"],\n",
    "    \"s\": [\"sh\", \"shh\"],\n",
    "    \"sh\": [\"s\", \"shh\"],\n",
    "    \"shh\": [\"s\", \"sh\"]\n",
    "}\n",
    "\n",
    "# Additional consonant variations\n",
    "consonant_map = {\n",
    "    \"chh\": [\"x\", \"ch\", \"xw\", \"xah\"],\n",
    "    \"e\": [\"ye\", \"ya\"],\n",
    "    \"pha\": [\"fa\"],\n",
    "    \"a\": [\"w\",],\n",
    "    'T': [\"t\", \"tt\"],\n",
    "    'Th': [\"Th\"],\n",
    "    'D': [\"d\"],\n",
    "    'Dh': [\"dh\"],\n",
    "    'v': ['b', 'bh'],\n",
    "    'b': ['v'],\n",
    "    'bh': ['v']\n",
    "}\n",
    "\n",
    "last_word_check_list = ['w','ah']\n",
    "\n",
    "def handle_repeated_chars(roman_word):\n",
    "        \"\"\"Reduce long repeated vowels (e.g., 'aaaa' → 'aa').\"\"\"\n",
    "        optimized_word = []\n",
    "        i = 0\n",
    "        while i < len(roman_word):\n",
    "            match = re.match(r\"([a-zA-Z])\\1{2,}\", roman_word[i:])\n",
    "            if match:\n",
    "                char = match.group(1)\n",
    "                optimized_word.append(char)  # Keep one repetition (aa, ee, etc.)\n",
    "                i += len(match.group(0))\n",
    "            else:\n",
    "                optimized_word.append(roman_word[i])\n",
    "                i += 1\n",
    "        return \"\".join(optimized_word)\n",
    "\n",
    "\n",
    "\n",
    "def generate_variations(word):\n",
    "    normalize_word = handle_repeated_chars(word)\n",
    "\n",
    "    new_words = [normalize_word]\n",
    "\n",
    "    for key, variations in consonant_map.items():\n",
    "        for variation in variations:\n",
    "            if variation in normalize_word and (key not in normalize_word or key in [\"e\"]):\n",
    "                normalize_word = normalize_word.replace(variation, key)\n",
    "    new_words.append(normalize_word)\n",
    "    # print('new_words', new_words)\n",
    "\n",
    "    new_variations = list(new_words)\n",
    "    # print('new_variations', new_variations)\n",
    "    for roman_word in new_words:\n",
    "        tokens = []\n",
    "        i = 0\n",
    "        while i < len(roman_word):\n",
    "            # print('roman_word', roman_word)\n",
    "            if i + 1 < len(roman_word) and roman_word[i:i+2] in variation_map:\n",
    "                if (i + 2 < len(roman_word)) and roman_word[i:i+2] in last_word_check_list:\n",
    "                    if roman_word[i] in variation_map:\n",
    "                        tokens.append(variation_map[roman_word[i]])\n",
    "                    else:\n",
    "                        tokens.append([roman_word[i]])\n",
    "                    i += 1\n",
    "                else:\n",
    "                    tokens.append(variation_map[roman_word[i:i+2]])\n",
    "                    i += 2\n",
    "            elif roman_word[i] in variation_map:\n",
    "                if (i + 2 < len(roman_word)) and roman_word[i] in last_word_check_list:\n",
    "                    tokens.append([roman_word[i]])\n",
    "                else:\n",
    "                    tokens.append(variation_map[roman_word[i]])\n",
    "                i += 1\n",
    "            else:\n",
    "                tokens.append([roman_word[i]])\n",
    "                i += 1\n",
    "            # print('tokens', tokens)\n",
    "\n",
    "        variations = [\"\".join(variant) for variant in itertools.product(*tokens)]\n",
    "        new_variations.extend(variations)\n",
    "\n",
    "    return set(new_variations)\n",
    "\n",
    "# Example usage\n",
    "\n",
    "def generate_devnagri_variations(variant):\n",
    "    latin_variations = generate_variations(variant)\n",
    "    # print('latin_variations', latin_variations)\n",
    "    devanagari_variations = []\n",
    "    print('Romanized variations', list(latin_variations))\n",
    "    for variant in latin_variations:\n",
    "        nepali = transliterate(variant, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
    "        devanagari_variations.append(nepali)\n",
    "    return devanagari_variations\n",
    "\n",
    "\n",
    "variant = \"ramro\"\n",
    "# variant = \"vahirw\"\n",
    "print('word:', variant)\n",
    "devanagari_variations = generate_devnagri_variations(variant)\n",
    "print('Devanagari variations:', devanagari_variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "PICKLE_FILE = \"dictionary/word_count.pkl\"  # Path to the saved pickle file\n",
    "\n",
    "def load_saved_word_count():\n",
    "    \"\"\"Load and return the word frequency dictionary from the pickle file.\"\"\"\n",
    "    if os.path.exists(PICKLE_FILE):\n",
    "        with open(PICKLE_FILE, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    else:\n",
    "        print(\"No saved word count dictionary found.\")\n",
    "        return {}  # Return an empty dictionary if the file doesn't exist\n",
    "\n",
    "# Usage\n",
    "saved_word_count = load_saved_word_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240683"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(saved_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def rank_variants_by_similarity(variants, nepali_dictionary):\n",
    "    \"\"\"\n",
    "    Rank the generated variants by their similarity to words in the Nepali dictionary using TF-IDF.\n",
    "\n",
    "    :param variants: List of transliterated Nepali variants.\n",
    "    :param nepali_dictionary: List of words in the Nepali dictionary.\n",
    "    :return: List of variants ordered by similarity along with matched dictionary word and similarity score.\n",
    "    \"\"\"\n",
    "    # Ensure both dictionary and variants are lists\n",
    "    nepali_dictionary = list(nepali_dictionary)\n",
    "\n",
    "    # Combine variants and dictionary into a single corpus\n",
    "    corpus = nepali_dictionary + variants\n",
    "\n",
    "    # Compute TF-IDF vectors\n",
    "    # vectorizer = TfidfVectorizer(analyzer='char')\n",
    "    vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(2, 4))\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    # Calculate similarity of each variant to the dictionary words\n",
    "    dictionary_size = len(nepali_dictionary)\n",
    "    variant_vectors = tfidf_matrix[dictionary_size:]\n",
    "    dictionary_vectors = tfidf_matrix[:dictionary_size]\n",
    "\n",
    "    similarities = cosine_similarity(variant_vectors, dictionary_vectors)\n",
    "\n",
    "    # Rank variants by maximum similarity to any dictionary word\n",
    "    ranked_variants = []\n",
    "    for i, variant in enumerate(variants):\n",
    "        max_sim_index = similarities[i].argmax()\n",
    "        matched_word = nepali_dictionary[max_sim_index]\n",
    "        similarity_score = similarities[i, max_sim_index]\n",
    "        ranked_variants.append((variant, matched_word, similarity_score))\n",
    "\n",
    "    ranked_variants.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    return ranked_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Romanized variations ['chhiTaii', 'chhiTaaii', 'xiitaai', 'chhiiTai', 'chhiiTaii', 'xiitaaii', 'xitai', 'xiitai', 'chhiiTaaii', 'chhiiTaai', 'xitaai', 'chhiTai', 'xitaaii', 'xitaii', 'xiitaii', 'chhiTaai']\n",
      "Devanagari variations: ['छिटैइ', 'छिटाई', 'क्षीताइ', 'छीटै', 'छीटैइ', 'क्षीताई', 'क्षितै', 'क्षीतै', 'छीटाई', 'छीटाइ', 'क्षिताइ', 'छिटै', 'क्षिताई', 'क्षितैइ', 'क्षीतैइ', 'छिटाइ']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_devnagri_variations(variant):\n",
    "    latin_variations = generate_variations(variant)\n",
    "    devanagari_variations = []\n",
    "    print('Romanized variations', list(latin_variations))\n",
    "    for variant in latin_variations:\n",
    "        nepali = transliterate(variant, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
    "        devanagari_variations.append(nepali)\n",
    "    return devanagari_variations\n",
    "\n",
    "\n",
    "\n",
    "variant = \"xitai\" # \"choto\"\n",
    "devanagari_variations = generate_devnagri_variations(variant)\n",
    "print('Devanagari variations:', devanagari_variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Matched Words:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('छिटै', 'छिटै', np.float64(1.0000000000000002)),\n",
       " ('क्षिताइ', 'क्षिता', np.float64(0.8544469615894122)),\n",
       " ('क्षिताई', 'क्षिता', np.float64(0.8402461404736585)),\n",
       " ('छिटाइ', 'छिटा', np.float64(0.8123941888442923)),\n",
       " ('छिटाई', 'छिटा', np.float64(0.7862377861886304)),\n",
       " ('छिटैइ', 'छिटै', np.float64(0.7398916777853775)),\n",
       " ('क्षितै', 'रक्षित', np.float64(0.6448526846991487)),\n",
       " ('क्षीतै', 'दिक्षीत', np.float64(0.6206501854178037)),\n",
       " ('क्षीताइ', 'दिक्षीत', np.float64(0.5765564718126105)),\n",
       " ('क्षीताई', 'दिक्षीत', np.float64(0.5748823392918202)),\n",
       " ('क्षीतैइ', 'दिक्षीत', np.float64(0.5111001768896763)),\n",
       " ('क्षितैइ', 'रक्षित', np.float64(0.5087940067345638)),\n",
       " ('छीटाइ', 'ट्रीटाइज', np.float64(0.4183781457221604)),\n",
       " ('छीटाई', 'टाई', np.float64(0.39788749732582235)),\n",
       " ('छीटै', 'छी', np.float64(0.3173725426977561)),\n",
       " ('छीटैइ', 'छी', np.float64(0.24445992302796052))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEPALI_DICTIONARY= saved_word_count\n",
    "top_matched_words = rank_variants_by_similarity(devanagari_variations, NEPALI_DICTIONARY)\n",
    "\n",
    "print(\"\\nTop 5 Matched Words:\")\n",
    "top_matched_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "from metaphone import doublemetaphone\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"files/words_devnagri_root.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Devanagari</th>\n",
       "      <th>Root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xata</td>\n",
       "      <td>छट</td>\n",
       "      <td>छट</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xatw</td>\n",
       "      <td>छट</td>\n",
       "      <td>छट</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xodyo</td>\n",
       "      <td>छोड्यो</td>\n",
       "      <td>छोड्यो</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xoto</td>\n",
       "      <td>छोटो</td>\n",
       "      <td>छोटो</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sidhai</td>\n",
       "      <td>सिधै</td>\n",
       "      <td>सिधा</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Words Devanagari     Root\n",
       "0    xata         छट       छट\n",
       "1    xatw         छट       छट\n",
       "2   xodyo     छोड्यो   छोड्यो\n",
       "3    xoto       छोटो     छोटो\n",
       "4  sidhai       सिधै     सिधा"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('Devanagari')['Words'].apply(list).reset_index()\n",
    "\n",
    "# Filter to only include entries with more than one word\n",
    "filtered = grouped[grouped['Words'].apply(len) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Devanagari</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>परियो</td>\n",
       "      <td>[pariyo, pareyo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>पर्यो</td>\n",
       "      <td>[paryoo, paryo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>पुरै</td>\n",
       "      <td>[paurai, purae]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>भएर</td>\n",
       "      <td>[vayerw, vaera, vayeraw, bhaera]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>भएर</td>\n",
       "      <td>[vayera, vayeraw, vayara, vayerw, bhayera]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>सिधै</td>\n",
       "      <td>[sidhai, siddai]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Devanagari                                       Words\n",
       "3       परियो                            [pariyo, pareyo]\n",
       "4       पर्यो                             [paryoo, paryo]\n",
       "5        पुरै                             [paurai, purae]\n",
       "7         भएर            [vayerw, vaera, vayeraw, bhaera]\n",
       "16        भएर  [vayera, vayeraw, vayara, vayerw, bhayera]\n",
       "18       सिधै                            [sidhai, siddai]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Multiple mappings found: {('पारियो',): 1, ('पारीयो',): 1}\n",
      "✅ Keeping only the most frequent one: '('पारियो',)' — Adding 1\n",
      "❌ Multiple mappings found: {('पार्यु',): 1, ('पार्यो',): 1}\n",
      "✅ Keeping only the most frequent one: '('पार्यु',)' — Adding 1\n",
      "❌ Multiple mappings found: {('पौराई',): 1, ('पुरै',): 1}\n",
      "✅ Keeping only the most frequent one: '('पौराई',)' — Adding 1\n",
      "❌ Multiple mappings found: {('वयेर',): 1, ('बैरा',): 2, ('भएर',): 1}\n",
      "✅ Keeping only the most frequent one: '('बैरा',)' — Adding 2\n",
      "❌ Multiple mappings found: {('बैरा',): 2, ('वायर',): 1, ('वयेर',): 1, ('भयेर',): 1}\n",
      "✅ Keeping only the most frequent one: '('बैरा',)' — Adding 2\n",
      "❌ Multiple mappings found: {('सिधै',): 1, ('सिद्दै',): 1}\n",
      "✅ Keeping only the most frequent one: '('सिधै',)' — Adding 1\n",
      "accurate: 8 total: 17 percent0.47058823529411764\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "total = 0\n",
    "accurate = 0\n",
    "not_accurate = 0\n",
    "NEPALI_DICTIONARY = saved_word_count\n",
    "\n",
    "for nepali_word, variants in zip(filtered['Devanagari'], filtered['Words']):\n",
    "    # print(\"nepali_word\", nepali_word, 'variants', variants)\n",
    "    nepali_variations = []\n",
    "    for variant in variants:\n",
    "      total +=1\n",
    "      latin_variations = generate_variations(variant)\n",
    "      devanagari_variations = []\n",
    "      for new_variant in latin_variations:\n",
    "          nepali = transliterate(new_variant, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
    "          devanagari_variations.append(nepali)\n",
    "      top_matched_words = rank_variants_by_similarity(devanagari_variations, NEPALI_DICTIONARY)\n",
    "      nepali = top_matched_words[0][0] if top_matched_words else None\n",
    "      nepali_variations.append((nepali,))\n",
    "    # Count occurrences of each mapped Nepali word\n",
    "    counter = Counter(nepali_variations)\n",
    "    most_common_word, count = counter.most_common(1)[0]\n",
    "\n",
    "    if len(counter) == 1:\n",
    "        print(f\"✅ All variants map to the same Nepali word: '{most_common_word}' — Adding {count}\")\n",
    "        accurate += count\n",
    "    else:\n",
    "        print(f\"❌ Multiple mappings found: {dict(counter)}\")\n",
    "        print(f\"✅ Keeping only the most frequent one: '{most_common_word}' — Adding {count}\")\n",
    "        accurate += count\n",
    "      # if nepali == nepali_word:\n",
    "      #   accurate +=1\n",
    "      # else:\n",
    "      #   not_accurate +=1\n",
    "      #   print(f'{variant}-->{nepali_word}-->{nepali}')\n",
    "print(f'accurate: {accurate} total: {total} percent{accurate/total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

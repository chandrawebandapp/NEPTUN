{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: bigriyako\n",
      "Romanized variations ['biigriieko', 'biigrieko', 'biigriyako', 'bigrieko', 'biigriiyaako', 'bigriyaako', 'biigrieeko', 'biigriiyako', 'bigriieeko', 'biigriieeko', 'bigriiyaako', 'bigriyako', 'bigrieeko', 'bigriiyako', 'biigriyaako', 'bigriieko']\n",
      "Devanagari variations: ['‡§¨‡•Ä‡§ó‡•ç‡§∞‡•Ä‡§è‡§ï‡•ã', '‡§¨‡•Ä‡§ó‡•ç‡§∞‡§ø‡§è‡§ï‡•ã', '‡§¨‡•Ä‡§ó‡•ç‡§∞‡§ø‡§Ø‡§ï‡•ã', '‡§¨‡§ø‡§ó‡•ç‡§∞‡§ø‡§è‡§ï‡•ã', '‡§¨‡•Ä‡§ó‡•ç‡§∞‡•Ä‡§Ø‡§æ‡§ï‡•ã', '‡§¨‡§ø‡§ó‡•ç‡§∞‡§ø‡§Ø‡§æ‡§ï‡•ã', '‡§¨‡•Ä‡§ó‡•ç‡§∞‡§ø‡§à‡§ï‡•ã', '‡§¨‡•Ä‡§ó‡•ç‡§∞‡•Ä‡§Ø‡§ï‡•ã', '‡§¨‡§ø‡§ó‡•ç‡§∞‡•Ä‡§à‡§ï‡•ã', '‡§¨‡•Ä‡§ó‡•ç‡§∞‡•Ä‡§à‡§ï‡•ã', '‡§¨‡§ø‡§ó‡•ç‡§∞‡•Ä‡§Ø‡§æ‡§ï‡•ã', '‡§¨‡§ø‡§ó‡•ç‡§∞‡§ø‡§Ø‡§ï‡•ã', '‡§¨‡§ø‡§ó‡•ç‡§∞‡§ø‡§à‡§ï‡•ã', '‡§¨‡§ø‡§ó‡•ç‡§∞‡•Ä‡§Ø‡§ï‡•ã', '‡§¨‡•Ä‡§ó‡•ç‡§∞‡§ø‡§Ø‡§æ‡§ï‡•ã', '‡§¨‡§ø‡§ó‡•ç‡§∞‡•Ä‡§è‡§ï‡•ã']\n"
     ]
    }
   ],
   "source": [
    "from indic_transliteration import sanscript\n",
    "from indic_transliteration.sanscript import transliterate\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "# Define phonetic variations\n",
    "variation_map = {\n",
    "    \"aa\": [\"a\", \"aa\"],\n",
    "    \"a\": [\"a\", \"aa\"],\n",
    "    \"ah\": [\"a\", \"ah\", \"aa\"],\n",
    "    \"w\": [\"a\", \"w\"],\n",
    "    \"e\": [\"e\", \"ee\"],\n",
    "    \"ee\": [\"e\", \"ee\"],\n",
    "    \"i\": [\"i\", \"ii\"],\n",
    "    \"o\": [\"o\"],\n",
    "    \"oo\": [\"u\", \"uu\", \"oo\"],\n",
    "    \"u\": [\"u\", \"uu\"],\n",
    "    \"uu\": [\"u\", \"uu\"],\n",
    "    \"ae\": [\"ai\"],\n",
    "    \"s\": [\"sh\", \"shh\"],\n",
    "    \"sh\": [\"s\", \"shh\"],\n",
    "    \"shh\": [\"s\", \"sh\"]\n",
    "}\n",
    "\n",
    "# Additional consonant variations\n",
    "consonant_map = {\n",
    "    \"chh\": [\"x\", \"ch\", \"xw\", \"xah\"],\n",
    "    \"e\": [\"ye\", \"ya\"],\n",
    "    \"pha\": [\"fa\"],\n",
    "    \"a\": [\"w\",],\n",
    "    'T': [\"t\", \"tt\"],\n",
    "    'Th': [\"Th\"],\n",
    "    'D': [\"d\"],\n",
    "    'Dh': [\"dh\"],\n",
    "    'v': ['b', 'bh'],\n",
    "    'b': ['v'],\n",
    "    'bh': ['v']\n",
    "}\n",
    "\n",
    "last_word_check_list = ['w','ah']\n",
    "\n",
    "def handle_repeated_chars(roman_word):\n",
    "        \"\"\"Reduce long repeated vowels (e.g., 'aaaa' ‚Üí 'aa').\"\"\"\n",
    "        optimized_word = []\n",
    "        i = 0\n",
    "        while i < len(roman_word):\n",
    "            match = re.match(r\"([a-zA-Z])\\1{2,}\", roman_word[i:])\n",
    "            if match:\n",
    "                char = match.group(1)\n",
    "                optimized_word.append(char)  # Keep one repetition (aa, ee, etc.)\n",
    "                i += len(match.group(0))\n",
    "            else:\n",
    "                optimized_word.append(roman_word[i])\n",
    "                i += 1\n",
    "        return \"\".join(optimized_word)\n",
    "\n",
    "\n",
    "\n",
    "def generate_variations(word):\n",
    "    normalize_word = handle_repeated_chars(word)\n",
    "\n",
    "    new_words = [normalize_word]\n",
    "\n",
    "    for key, variations in consonant_map.items():\n",
    "        for variation in variations:\n",
    "            if variation in normalize_word and (key not in normalize_word or key in [\"e\"]):\n",
    "                normalize_word = normalize_word.replace(variation, key)\n",
    "    new_words.append(normalize_word)\n",
    "    # print('new_words', new_words)\n",
    "\n",
    "    new_variations = list(new_words)\n",
    "    # print('new_variations', new_variations)\n",
    "    for roman_word in new_words:\n",
    "        tokens = []\n",
    "        i = 0\n",
    "        while i < len(roman_word):\n",
    "            # print('roman_word', roman_word)\n",
    "            if i + 1 < len(roman_word) and roman_word[i:i+2] in variation_map:\n",
    "                if (i + 2 < len(roman_word)) and roman_word[i:i+2] in last_word_check_list:\n",
    "                    if roman_word[i] in variation_map:\n",
    "                        tokens.append(variation_map[roman_word[i]])\n",
    "                    else:\n",
    "                        tokens.append([roman_word[i]])\n",
    "                    i += 1\n",
    "                else:\n",
    "                    tokens.append(variation_map[roman_word[i:i+2]])\n",
    "                    i += 2\n",
    "            elif roman_word[i] in variation_map:\n",
    "                if (i + 2 < len(roman_word)) and roman_word[i] in last_word_check_list:\n",
    "                    tokens.append([roman_word[i]])\n",
    "                else:\n",
    "                    tokens.append(variation_map[roman_word[i]])\n",
    "                i += 1\n",
    "            else:\n",
    "                tokens.append([roman_word[i]])\n",
    "                i += 1\n",
    "            # print('tokens', tokens)\n",
    "\n",
    "        variations = [\"\".join(variant) for variant in itertools.product(*tokens)]\n",
    "        new_variations.extend(variations)\n",
    "\n",
    "    return set(new_variations)\n",
    "\n",
    "# Example usage\n",
    "\n",
    "def generate_devnagri_variations(variant):\n",
    "    latin_variations = generate_variations(variant)\n",
    "    # print('latin_variations', latin_variations)\n",
    "    devanagari_variations = []\n",
    "    print('Romanized variations', list(latin_variations))\n",
    "    for variant in latin_variations:\n",
    "        nepali = transliterate(variant, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
    "        devanagari_variations.append(nepali)\n",
    "    return devanagari_variations\n",
    "\n",
    "\n",
    "variant = \"bigriyako\"\n",
    "# variant = \"vahirw\"\n",
    "print('word:', variant)\n",
    "devanagari_variations = generate_devnagri_variations(variant)\n",
    "print('Devanagari variations:', devanagari_variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "PICKLE_FILE = \"dictionary/word_count.pkl\"  # Path to the saved pickle file\n",
    "\n",
    "def load_saved_word_count():\n",
    "    \"\"\"Load and return the word frequency dictionary from the pickle file.\"\"\"\n",
    "    if os.path.exists(PICKLE_FILE):\n",
    "        with open(PICKLE_FILE, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    else:\n",
    "        print(\"No saved word count dictionary found.\")\n",
    "        return {}  # Return an empty dictionary if the file doesn't exist\n",
    "\n",
    "# Usage\n",
    "saved_word_count = load_saved_word_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240683"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(saved_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def rank_variants_by_similarity(variants, nepali_dictionary):\n",
    "    \"\"\"\n",
    "    Rank the generated variants by their similarity to words in the Nepali dictionary using TF-IDF.\n",
    "\n",
    "    :param variants: List of transliterated Nepali variants.\n",
    "    :param nepali_dictionary: List of words in the Nepali dictionary.\n",
    "    :return: List of variants ordered by similarity along with matched dictionary word and similarity score.\n",
    "    \"\"\"\n",
    "    # Ensure both dictionary and variants are lists\n",
    "    nepali_dictionary = list(nepali_dictionary)\n",
    "\n",
    "    # Combine variants and dictionary into a single corpus\n",
    "    corpus = nepali_dictionary + variants\n",
    "\n",
    "    # Compute TF-IDF vectors\n",
    "    # vectorizer = TfidfVectorizer(analyzer='char')\n",
    "    vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(2, 4))\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    # Calculate similarity of each variant to the dictionary words\n",
    "    dictionary_size = len(nepali_dictionary)\n",
    "    variant_vectors = tfidf_matrix[dictionary_size:]\n",
    "    dictionary_vectors = tfidf_matrix[:dictionary_size]\n",
    "\n",
    "    similarities = cosine_similarity(variant_vectors, dictionary_vectors)\n",
    "\n",
    "    # Rank variants by maximum similarity to any dictionary word\n",
    "    ranked_variants = []\n",
    "    for i, variant in enumerate(variants):\n",
    "        max_sim_index = similarities[i].argmax()\n",
    "        matched_word = nepali_dictionary[max_sim_index]\n",
    "        similarity_score = similarities[i, max_sim_index]\n",
    "        ranked_variants.append((variant, matched_word, similarity_score))\n",
    "\n",
    "    ranked_variants.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    return ranked_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Romanized variations ['biigreko', 'bigreeko', 'bigreko', 'biigreeko']\n",
      "Devanagari variations: ['‡§¨‡•Ä‡§ó‡•ç‡§∞‡•á‡§ï‡•ã', '‡§¨‡§ø‡§ó‡•ç‡§∞‡•Ä‡§ï‡•ã', '‡§¨‡§ø‡§ó‡•ç‡§∞‡•á‡§ï‡•ã', '‡§¨‡•Ä‡§ó‡•ç‡§∞‡•Ä‡§ï‡•ã']\n",
      "\n",
      "Top 5 Matched Words:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('‡§¨‡•Ä‡§ó‡•ç‡§∞‡•á‡§ï‡•ã', '‡§¨‡•Ä‡§ó‡•ç‡§∞‡•á‡§ï‡•ã', np.float64(1.0)),\n",
       " ('‡§¨‡§ø‡§ó‡•ç‡§∞‡•á‡§ï‡•ã', '‡§¨‡§ø‡§ó‡•ç‡§∞‡•á‡§ï‡•ã', np.float64(1.0)),\n",
       " ('‡§¨‡§ø‡§ó‡•ç‡§∞‡•Ä‡§ï‡•ã', '‡§¨‡§ø‡§ó‡•ç‡§∞‡•Ä', np.float64(0.8490152233079645)),\n",
       " ('‡§¨‡•Ä‡§ó‡•ç‡§∞‡•Ä‡§ï‡•ã', '‡§¨‡•Ä‡§ó‡•ç‡§∞‡•á‡§°', np.float64(0.6655647416719088))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def generate_devnagri_variations(variant):\n",
    "    latin_variations = generate_variations(variant)\n",
    "    devanagari_variations = []\n",
    "    print('Romanized variations', list(latin_variations))\n",
    "    for variant in latin_variations:\n",
    "        nepali = transliterate(variant, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
    "        devanagari_variations.append(nepali)\n",
    "    return devanagari_variations\n",
    "\n",
    "\n",
    "\n",
    "variant = \"bigreko\" # \"choto\"\n",
    "devanagari_variations = generate_devnagri_variations(variant)\n",
    "print('Devanagari variations:', devanagari_variations)\n",
    "\n",
    "NEPALI_DICTIONARY= saved_word_count\n",
    "top_matched_words = rank_variants_by_similarity(devanagari_variations, NEPALI_DICTIONARY)\n",
    "\n",
    "print(\"\\nTop 5 Matched Words:\")\n",
    "top_matched_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Matched Words:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('‡§¨‡•Ä‡§ó‡•ç‡§∞‡•á‡§ï‡•ã', '‡§¨‡•Ä‡§ó‡•ç‡§∞‡•á‡§ï‡•ã', np.float64(1.0)),\n",
       " ('‡§¨‡§ø‡§ó‡•ç‡§∞‡•á‡§ï‡•ã', '‡§¨‡§ø‡§ó‡•ç‡§∞‡•á‡§ï‡•ã', np.float64(1.0)),\n",
       " ('‡§¨‡§ø‡§ó‡•ç‡§∞‡•Ä‡§ï‡•ã', '‡§¨‡§ø‡§ó‡•ç‡§∞‡•Ä', np.float64(0.8490152233079645)),\n",
       " ('‡§¨‡•Ä‡§ó‡•ç‡§∞‡•Ä‡§ï‡•ã', '‡§¨‡•Ä‡§ó‡•ç‡§∞‡•á‡§°', np.float64(0.6655647416719088))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEPALI_DICTIONARY= saved_word_count\n",
    "top_matched_words = rank_variants_by_similarity(devanagari_variations, NEPALI_DICTIONARY)\n",
    "\n",
    "print(\"\\nTop 5 Matched Words:\")\n",
    "top_matched_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "from metaphone import doublemetaphone\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"files/multi_words_devnagri_root.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Devanagari</th>\n",
       "      <th>Root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raamrai</td>\n",
       "      <td>‡§∞‡§æ‡§Æ‡•ç‡§∞‡•à</td>\n",
       "      <td>‡§∞‡§æ‡§Æ‡•ç‡§∞‡§æ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>raamro</td>\n",
       "      <td>‡§∞‡§æ‡§Æ‡•ç‡§∞‡•ã</td>\n",
       "      <td>‡§∞‡§æ‡§Æ‡•ç‡§∞‡§æ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fohor</td>\n",
       "      <td>‡§´‡•ã‡§π‡•ã‡§∞</td>\n",
       "      <td>‡§´‡•ã‡§π‡•ã‡§∞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xodyo</td>\n",
       "      <td>‡§õ‡•ã‡§°‡•ç‡§Ø‡•ã</td>\n",
       "      <td>‡§õ‡•ã‡§°‡•ç‡§Ø‡•ã</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sidhai</td>\n",
       "      <td>‡§∏‡§ø‡§ß‡•à</td>\n",
       "      <td>‡§∏‡§ø‡§ß‡§æ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Words Devanagari     Root\n",
       "0  raamrai     ‡§∞‡§æ‡§Æ‡•ç‡§∞‡•à   ‡§∞‡§æ‡§Æ‡•ç‡§∞‡§æ\n",
       "1   raamro     ‡§∞‡§æ‡§Æ‡•ç‡§∞‡•ã   ‡§∞‡§æ‡§Æ‡•ç‡§∞‡§æ\n",
       "2    fohor      ‡§´‡•ã‡§π‡•ã‡§∞    ‡§´‡•ã‡§π‡•ã‡§∞\n",
       "3    xodyo     ‡§õ‡•ã‡§°‡•ç‡§Ø‡•ã   ‡§õ‡•ã‡§°‡•ç‡§Ø‡•ã\n",
       "4   sidhai       ‡§∏‡§ø‡§ß‡•à     ‡§∏‡§ø‡§ß‡§æ"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('Devanagari')['Words'].apply(list).reset_index()\n",
    "\n",
    "# Filter to only include entries with more than one word\n",
    "filtered = grouped[grouped['Words'].apply(len) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Devanagari</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡§ñ‡•Å‡§≤‡•á‡§ï‡•ã</td>\n",
       "      <td>[khuuleko, khuleko]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡§õ‡•à‡§®</td>\n",
       "      <td>['xhaina', 'xiana', 'xaena', chhaina]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡§ü‡§ø‡§ï‡•ç‡§õ</td>\n",
       "      <td>[tikcha, tikxa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡§™‡§∞‡§ø‡§Ø‡•ã</td>\n",
       "      <td>[pariyo, pareyo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡§™‡§∞‡•ç‡§Ø‡•ã</td>\n",
       "      <td>[paryoo, paryo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>‡§π‡•Å‡§®‡•á</td>\n",
       "      <td>[hune, hunay]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>‡§π‡•Å‡§®‡•á‡§õ</td>\n",
       "      <td>[hunexa, hunexw, hunexa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>‡§π‡•Å‡§®‡•ç‡§õ</td>\n",
       "      <td>[hunchha, hunxa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>‡§π‡•à</td>\n",
       "      <td>[haii, hae]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>‡§π‡•ã‡§≤‡§æ</td>\n",
       "      <td>[hola, holaa]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Devanagari                                  Words\n",
       "0       ‡§ñ‡•Å‡§≤‡•á‡§ï‡•ã                    [khuuleko, khuleko]\n",
       "1          ‡§õ‡•à‡§®  ['xhaina', 'xiana', 'xaena', chhaina]\n",
       "2        ‡§ü‡§ø‡§ï‡•ç‡§õ                        [tikcha, tikxa]\n",
       "3        ‡§™‡§∞‡§ø‡§Ø‡•ã                       [pariyo, pareyo]\n",
       "4        ‡§™‡§∞‡•ç‡§Ø‡•ã                        [paryoo, paryo]\n",
       "..         ...                                    ...\n",
       "113       ‡§π‡•Å‡§®‡•á                          [hune, hunay]\n",
       "114      ‡§π‡•Å‡§®‡•á‡§õ               [hunexa, hunexw, hunexa]\n",
       "115      ‡§π‡•Å‡§®‡•ç‡§õ                       [hunchha, hunxa]\n",
       "116         ‡§π‡•à                            [haii, hae]\n",
       "117       ‡§π‡•ã‡§≤‡§æ                          [hola, holaa]\n",
       "\n",
       "[118 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurate: 220, total: 302, percent: 0.73\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "total = 0\n",
    "accurate = 0\n",
    "not_accurate = 0\n",
    "NEPALI_DICTIONARY = saved_word_count\n",
    "\n",
    "for nepali_word, variants in zip(filtered['Devanagari'], filtered['Words']):\n",
    "    nepali_variations = []\n",
    "    for variant in variants:\n",
    "        total += 1\n",
    "        latin_variations = generate_variations(variant)\n",
    "        devanagari_variations = []\n",
    "        for new_variant in latin_variations:\n",
    "            nepali = transliterate(new_variant, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
    "            devanagari_variations.append(nepali)\n",
    "        top_matched_words = rank_variants_by_similarity(devanagari_variations, NEPALI_DICTIONARY)\n",
    "        nepali = top_matched_words[0][1] if top_matched_words else None\n",
    "        nepali_variations.append((nepali, variant))  # store variant too for debugging\n",
    "\n",
    "    # Find the most common mapped word\n",
    "    mapped_words_only = [x[0] for x in nepali_variations]\n",
    "    counter = Counter(mapped_words_only)\n",
    "    most_common_word, count = counter.most_common(1)[0]\n",
    "\n",
    "    # Now keep only those variants where mapped word == most_common_word\n",
    "    filtered_nepali_variations = [\n",
    "        (mapped_word, variant) for mapped_word, variant in nepali_variations if mapped_word == most_common_word\n",
    "    ]\n",
    "\n",
    "    if len(counter) == 1:\n",
    "        # print(f\"‚úÖ All variants map to the same Nepali word: '{most_common_word}' ‚Äî Adding {count}\")\n",
    "        accurate += count\n",
    "    else:\n",
    "        # print(f\"‚ùå Multiple mappings found: {dict(counter)}\")\n",
    "        # print(f\"‚úÖ Keeping only the most frequent one: '{most_common_word}' ‚Äî Adding {count}\")\n",
    "        accurate += count\n",
    "\n",
    "    # Now check mismatches based on filtered mappings\n",
    "    for mapped_word, variant in nepali_variations:\n",
    "        if mapped_word != nepali_word:\n",
    "            # print(f\"üîÅ Mismatch: Variant '{variant}' ‚Üí Mapped '{mapped_word}', Expected '{nepali_word}'\")\n",
    "            not_accurate += 1\n",
    "\n",
    "\n",
    "print(f'accurate: {accurate}, total: {total}, percent: {accurate / total:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

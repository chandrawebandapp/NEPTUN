{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: bigriyako\n",
      "Romanized variations ['biigriieko', 'biigrieko', 'biigriyako', 'bigrieko', 'biigriiyaako', 'bigriyaako', 'biigrieeko', 'biigriiyako', 'bigriieeko', 'biigriieeko', 'bigriiyaako', 'bigriyako', 'bigrieeko', 'bigriiyako', 'biigriyaako', 'bigriieko']\n",
      "Devanagari variations: ['बीग्रीएको', 'बीग्रिएको', 'बीग्रियको', 'बिग्रिएको', 'बीग्रीयाको', 'बिग्रियाको', 'बीग्रिईको', 'बीग्रीयको', 'बिग्रीईको', 'बीग्रीईको', 'बिग्रीयाको', 'बिग्रियको', 'बिग्रिईको', 'बिग्रीयको', 'बीग्रियाको', 'बिग्रीएको']\n"
     ]
    }
   ],
   "source": [
    "from indic_transliteration import sanscript\n",
    "from indic_transliteration.sanscript import transliterate\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "# Define phonetic variations\n",
    "variation_map = {\n",
    "    \"aa\": [\"a\", \"aa\"],\n",
    "    \"a\": [\"a\", \"aa\"],\n",
    "    \"ah\": [\"a\", \"ah\", \"aa\"],\n",
    "    \"w\": [\"a\", \"w\"],\n",
    "    \"e\": [\"e\", \"ee\"],\n",
    "    \"ee\": [\"e\", \"ee\"],\n",
    "    \"i\": [\"i\", \"ii\"],\n",
    "    \"o\": [\"o\"],\n",
    "    \"oo\": [\"u\", \"uu\", \"oo\"],\n",
    "    \"u\": [\"u\", \"uu\"],\n",
    "    \"uu\": [\"u\", \"uu\"],\n",
    "    \"ae\": [\"ai\"],\n",
    "    \"s\": [\"sh\", \"shh\"],\n",
    "    \"sh\": [\"s\", \"shh\"],\n",
    "    \"shh\": [\"s\", \"sh\"]\n",
    "}\n",
    "\n",
    "# Additional consonant variations\n",
    "consonant_map = {\n",
    "    \"chh\": [\"x\", \"ch\", \"xw\", \"xah\"],\n",
    "    \"e\": [\"ye\", \"ya\"],\n",
    "    \"pha\": [\"fa\"],\n",
    "    \"a\": [\"w\",],\n",
    "    'T': [\"t\", \"tt\"],\n",
    "    'Th': [\"Th\"],\n",
    "    'D': [\"d\"],\n",
    "    'Dh': [\"dh\"],\n",
    "    'v': ['b', 'bh'],\n",
    "    'b': ['v'],\n",
    "    'bh': ['v']\n",
    "}\n",
    "\n",
    "last_word_check_list = ['w','ah']\n",
    "\n",
    "def handle_repeated_chars(roman_word):\n",
    "        \"\"\"Reduce long repeated vowels (e.g., 'aaaa' → 'aa').\"\"\"\n",
    "        optimized_word = []\n",
    "        i = 0\n",
    "        while i < len(roman_word):\n",
    "            match = re.match(r\"([a-zA-Z])\\1{2,}\", roman_word[i:])\n",
    "            if match:\n",
    "                char = match.group(1)\n",
    "                optimized_word.append(char)  # Keep one repetition (aa, ee, etc.)\n",
    "                i += len(match.group(0))\n",
    "            else:\n",
    "                optimized_word.append(roman_word[i])\n",
    "                i += 1\n",
    "        return \"\".join(optimized_word)\n",
    "\n",
    "\n",
    "\n",
    "def generate_variations(word):\n",
    "    normalize_word = handle_repeated_chars(word)\n",
    "\n",
    "    new_words = [normalize_word]\n",
    "\n",
    "    for key, variations in consonant_map.items():\n",
    "        for variation in variations:\n",
    "            if variation in normalize_word and (key not in normalize_word or key in [\"e\"]):\n",
    "                normalize_word = normalize_word.replace(variation, key)\n",
    "    new_words.append(normalize_word)\n",
    "    # print('new_words', new_words)\n",
    "\n",
    "    new_variations = list(new_words)\n",
    "    # print('new_variations', new_variations)\n",
    "    for roman_word in new_words:\n",
    "        tokens = []\n",
    "        i = 0\n",
    "        while i < len(roman_word):\n",
    "            # print('roman_word', roman_word)\n",
    "            if i + 1 < len(roman_word) and roman_word[i:i+2] in variation_map:\n",
    "                if (i + 2 < len(roman_word)) and roman_word[i:i+2] in last_word_check_list:\n",
    "                    if roman_word[i] in variation_map:\n",
    "                        tokens.append(variation_map[roman_word[i]])\n",
    "                    else:\n",
    "                        tokens.append([roman_word[i]])\n",
    "                    i += 1\n",
    "                else:\n",
    "                    tokens.append(variation_map[roman_word[i:i+2]])\n",
    "                    i += 2\n",
    "            elif roman_word[i] in variation_map:\n",
    "                if (i + 2 < len(roman_word)) and roman_word[i] in last_word_check_list:\n",
    "                    tokens.append([roman_word[i]])\n",
    "                else:\n",
    "                    tokens.append(variation_map[roman_word[i]])\n",
    "                i += 1\n",
    "            else:\n",
    "                tokens.append([roman_word[i]])\n",
    "                i += 1\n",
    "            # print('tokens', tokens)\n",
    "\n",
    "        variations = [\"\".join(variant) for variant in itertools.product(*tokens)]\n",
    "        new_variations.extend(variations)\n",
    "\n",
    "    return set(new_variations)\n",
    "\n",
    "# Example usage\n",
    "\n",
    "def generate_devnagri_variations(variant):\n",
    "    latin_variations = generate_variations(variant)\n",
    "    # print('latin_variations', latin_variations)\n",
    "    devanagari_variations = []\n",
    "    print('Romanized variations', list(latin_variations))\n",
    "    for variant in latin_variations:\n",
    "        nepali = transliterate(variant, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
    "        devanagari_variations.append(nepali)\n",
    "    return devanagari_variations\n",
    "\n",
    "\n",
    "variant = \"bigriyako\"\n",
    "# variant = \"vahirw\"\n",
    "print('word:', variant)\n",
    "devanagari_variations = generate_devnagri_variations(variant)\n",
    "print('Devanagari variations:', devanagari_variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "PICKLE_FILE = \"dictionary/word_count.pkl\"  # Path to the saved pickle file\n",
    "\n",
    "def load_saved_word_count():\n",
    "    \"\"\"Load and return the word frequency dictionary from the pickle file.\"\"\"\n",
    "    if os.path.exists(PICKLE_FILE):\n",
    "        with open(PICKLE_FILE, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    else:\n",
    "        print(\"No saved word count dictionary found.\")\n",
    "        return {}  # Return an empty dictionary if the file doesn't exist\n",
    "\n",
    "# Usage\n",
    "saved_word_count = load_saved_word_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240683"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(saved_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def rank_variants_by_similarity(variants, nepali_dictionary):\n",
    "    \"\"\"\n",
    "    Rank the generated variants by their similarity to words in the Nepali dictionary using TF-IDF.\n",
    "\n",
    "    :param variants: List of transliterated Nepali variants.\n",
    "    :param nepali_dictionary: List of words in the Nepali dictionary.\n",
    "    :return: List of variants ordered by similarity along with matched dictionary word and similarity score.\n",
    "    \"\"\"\n",
    "    # Ensure both dictionary and variants are lists\n",
    "    nepali_dictionary = list(nepali_dictionary)\n",
    "\n",
    "    # Combine variants and dictionary into a single corpus\n",
    "    corpus = nepali_dictionary + variants\n",
    "\n",
    "    # Compute TF-IDF vectors\n",
    "    # vectorizer = TfidfVectorizer(analyzer='char')\n",
    "    vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(2, 4))\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    # Calculate similarity of each variant to the dictionary words\n",
    "    dictionary_size = len(nepali_dictionary)\n",
    "    variant_vectors = tfidf_matrix[dictionary_size:]\n",
    "    dictionary_vectors = tfidf_matrix[:dictionary_size]\n",
    "\n",
    "    similarities = cosine_similarity(variant_vectors, dictionary_vectors)\n",
    "\n",
    "    # Rank variants by maximum similarity to any dictionary word\n",
    "    ranked_variants = []\n",
    "    for i, variant in enumerate(variants):\n",
    "        max_sim_index = similarities[i].argmax()\n",
    "        matched_word = nepali_dictionary[max_sim_index]\n",
    "        similarity_score = similarities[i, max_sim_index]\n",
    "        ranked_variants.append((variant, matched_word, similarity_score))\n",
    "\n",
    "    ranked_variants.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    return ranked_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Romanized variations ['biigreko', 'bigreeko', 'bigreko', 'biigreeko']\n",
      "Devanagari variations: ['बीग्रेको', 'बिग्रीको', 'बिग्रेको', 'बीग्रीको']\n",
      "\n",
      "Top 5 Matched Words:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('बीग्रेको', 'बीग्रेको', np.float64(1.0)),\n",
       " ('बिग्रेको', 'बिग्रेको', np.float64(1.0)),\n",
       " ('बिग्रीको', 'बिग्री', np.float64(0.8490152233079645)),\n",
       " ('बीग्रीको', 'बीग्रेड', np.float64(0.6655647416719088))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def generate_devnagri_variations(variant):\n",
    "    latin_variations = generate_variations(variant)\n",
    "    devanagari_variations = []\n",
    "    print('Romanized variations', list(latin_variations))\n",
    "    for variant in latin_variations:\n",
    "        nepali = transliterate(variant, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
    "        devanagari_variations.append(nepali)\n",
    "    return devanagari_variations\n",
    "\n",
    "\n",
    "\n",
    "variant = \"bigreko\" # \"choto\"\n",
    "devanagari_variations = generate_devnagri_variations(variant)\n",
    "print('Devanagari variations:', devanagari_variations)\n",
    "\n",
    "NEPALI_DICTIONARY= saved_word_count\n",
    "top_matched_words = rank_variants_by_similarity(devanagari_variations, NEPALI_DICTIONARY)\n",
    "\n",
    "print(\"\\nTop 5 Matched Words:\")\n",
    "top_matched_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Matched Words:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('बीग्रेको', 'बीग्रेको', np.float64(1.0)),\n",
       " ('बिग्रेको', 'बिग्रेको', np.float64(1.0)),\n",
       " ('बिग्रीको', 'बिग्री', np.float64(0.8490152233079645)),\n",
       " ('बीग्रीको', 'बीग्रेड', np.float64(0.6655647416719088))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEPALI_DICTIONARY= saved_word_count\n",
    "top_matched_words = rank_variants_by_similarity(devanagari_variations, NEPALI_DICTIONARY)\n",
    "\n",
    "print(\"\\nTop 5 Matched Words:\")\n",
    "top_matched_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "from metaphone import doublemetaphone\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"files/multi_words_devnagri_root.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Devanagari</th>\n",
       "      <th>Root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raamrai</td>\n",
       "      <td>राम्रै</td>\n",
       "      <td>राम्रा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>raamro</td>\n",
       "      <td>राम्रो</td>\n",
       "      <td>राम्रा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fohor</td>\n",
       "      <td>फोहोर</td>\n",
       "      <td>फोहोर</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xodyo</td>\n",
       "      <td>छोड्यो</td>\n",
       "      <td>छोड्यो</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sidhai</td>\n",
       "      <td>सिधै</td>\n",
       "      <td>सिधा</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Words Devanagari     Root\n",
       "0  raamrai     राम्रै   राम्रा\n",
       "1   raamro     राम्रो   राम्रा\n",
       "2    fohor      फोहोर    फोहोर\n",
       "3    xodyo     छोड्यो   छोड्यो\n",
       "4   sidhai       सिधै     सिधा"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('Devanagari')['Words'].apply(list).reset_index()\n",
    "\n",
    "# Filter to only include entries with more than one word\n",
    "filtered = grouped[grouped['Words'].apply(len) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Devanagari</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>खुलेको</td>\n",
       "      <td>[khuuleko, khuleko]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>छैन</td>\n",
       "      <td>['xhaina', 'xiana', 'xaena', chhaina]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>टिक्छ</td>\n",
       "      <td>[tikcha, tikxa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>परियो</td>\n",
       "      <td>[pariyo, pareyo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>पर्यो</td>\n",
       "      <td>[paryoo, paryo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>हुने</td>\n",
       "      <td>[hune, hunay]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>हुनेछ</td>\n",
       "      <td>[hunexa, hunexw, hunexa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>हुन्छ</td>\n",
       "      <td>[hunchha, hunxa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>है</td>\n",
       "      <td>[haii, hae]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>होला</td>\n",
       "      <td>[hola, holaa]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Devanagari                                  Words\n",
       "0       खुलेको                    [khuuleko, khuleko]\n",
       "1          छैन  ['xhaina', 'xiana', 'xaena', chhaina]\n",
       "2        टिक्छ                        [tikcha, tikxa]\n",
       "3        परियो                       [pariyo, pareyo]\n",
       "4        पर्यो                        [paryoo, paryo]\n",
       "..         ...                                    ...\n",
       "113       हुने                          [hune, hunay]\n",
       "114      हुनेछ               [hunexa, hunexw, hunexa]\n",
       "115      हुन्छ                       [hunchha, hunxa]\n",
       "116         है                            [haii, hae]\n",
       "117       होला                          [hola, holaa]\n",
       "\n",
       "[118 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurate: 220, total: 302, percent: 0.73\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "total = 0\n",
    "accurate = 0\n",
    "not_accurate = 0\n",
    "NEPALI_DICTIONARY = saved_word_count\n",
    "\n",
    "for nepali_word, variants in zip(filtered['Devanagari'], filtered['Words']):\n",
    "    nepali_variations = []\n",
    "    for variant in variants:\n",
    "        total += 1\n",
    "        latin_variations = generate_variations(variant)\n",
    "        devanagari_variations = []\n",
    "        for new_variant in latin_variations:\n",
    "            nepali = transliterate(new_variant, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
    "            devanagari_variations.append(nepali)\n",
    "        top_matched_words = rank_variants_by_similarity(devanagari_variations, NEPALI_DICTIONARY)\n",
    "        nepali = top_matched_words[0][1] if top_matched_words else None\n",
    "        nepali_variations.append((nepali, variant))  # store variant too for debugging\n",
    "\n",
    "    # Find the most common mapped word\n",
    "    mapped_words_only = [x[0] for x in nepali_variations]\n",
    "    counter = Counter(mapped_words_only)\n",
    "    most_common_word, count = counter.most_common(1)[0]\n",
    "\n",
    "    # Now keep only those variants where mapped word == most_common_word\n",
    "    filtered_nepali_variations = [\n",
    "        (mapped_word, variant) for mapped_word, variant in nepali_variations if mapped_word == most_common_word\n",
    "    ]\n",
    "\n",
    "    if len(counter) == 1:\n",
    "        # print(f\"✅ All variants map to the same Nepali word: '{most_common_word}' — Adding {count}\")\n",
    "        accurate += count\n",
    "    else:\n",
    "        # print(f\"❌ Multiple mappings found: {dict(counter)}\")\n",
    "        # print(f\"✅ Keeping only the most frequent one: '{most_common_word}' — Adding {count}\")\n",
    "        accurate += count\n",
    "\n",
    "    # Now check mismatches based on filtered mappings\n",
    "    for mapped_word, variant in nepali_variations:\n",
    "        if mapped_word != nepali_word:\n",
    "            # print(f\"🔁 Mismatch: Variant '{variant}' → Mapped '{mapped_word}', Expected '{nepali_word}'\")\n",
    "            not_accurate += 1\n",
    "\n",
    "\n",
    "print(f'accurate: {accurate}, total: {total}, percent: {accurate / total:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

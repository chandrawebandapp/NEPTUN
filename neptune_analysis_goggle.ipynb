{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: ['FAILED_TO_PARSE_REQUEST_BODY']\n",
      "No suggestion found.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def transliterate_google_input_tools(text, lang='ne'):\n",
    "    url = \"https://inputtools.google.com/request?itc={}-t-i0-und&num=5\".format(lang)\n",
    "    \n",
    "    payload = [\"text\", text]\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        \n",
    "        if result[0] == 'SUCCESS':\n",
    "            devanagari_suggestions = result[1][0][1]\n",
    "            return devanagari_suggestions\n",
    "        else:\n",
    "            print(f\"Error: {result}\")\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(f\"Exception: {e}\")\n",
    "        return []\n",
    "\n",
    "# Example Usage\n",
    "roman_text = \"k gardai xa\"\n",
    "suggestions = transliterate_google_input_tools(roman_text)\n",
    "if suggestions:\n",
    "    print(f\"Suggestions for '{roman_text}': {suggestions}\")\n",
    "else:\n",
    "    print(\"No suggestion found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: vayerw\n",
      "Romanized variations ['vayeera', 'vayeerw', 'vaayeera', 'bairw', 'vaayerw', 'baira', 'vaayeerw', 'vaayera', 'vayera', 'baerw', 'vayerw']\n",
      "Devanagari variations: ['वयीर', 'वयीर्व्', 'वायीर', 'बैर्व्', 'वायेर्व्', 'बैर', 'वायीर्व्', 'वायेर', 'वयेर', 'बएर्व्', 'वयेर्व्']\n"
     ]
    }
   ],
   "source": [
    "from indic_transliteration import sanscript\n",
    "from indic_transliteration.sanscript import transliterate\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "# Define phonetic variations\n",
    "variation_map = {\n",
    "    \"aa\": [\"a\", \"aa\"],\n",
    "    \"a\": [\"a\", \"aa\"],\n",
    "    \"ah\": [\"a\", \"ah\", \"aa\"],\n",
    "    \"w\": [\"a\", \"w\"],\n",
    "    \"e\": [\"e\", \"ee\"],\n",
    "    \"ee\": [\"e\", \"ee\"],\n",
    "    \"i\": [\"i\", \"ii\"],\n",
    "    \"o\": [\"o\"],\n",
    "    \"oo\": [\"u\", \"uu\", \"oo\"],\n",
    "    \"u\": [\"u\", \"uu\"],\n",
    "    \"uu\": [\"u\", \"uu\"],\n",
    "    \"ae\": [\"ai\"],\n",
    "    \"s\": [\"sh\", \"shh\"],\n",
    "    \"sh\": [\"s\", \"shh\"],\n",
    "    \"shh\": [\"s\", \"sh\"]\n",
    "}\n",
    "\n",
    "# Additional consonant variations\n",
    "consonant_map = {\n",
    "    \"chh\": [\"x\", \"ch\", \"xw\", \"xah\"],\n",
    "    \"e\": [\"ye\", \"ya\"],\n",
    "    \"pha\": [\"fa\"],\n",
    "    \"a\": [\"w\",],\n",
    "    'T': [\"t\", \"tt\"],\n",
    "    'Th': [\"Th\"],\n",
    "    'D': [\"d\"],\n",
    "    'Dh': [\"dh\"],\n",
    "    'v': ['b', 'bh'],\n",
    "    'b': ['v'],\n",
    "    'bh': ['v']\n",
    "}\n",
    "\n",
    "last_word_check_list = ['w','ah']\n",
    "\n",
    "def handle_repeated_chars(roman_word):\n",
    "        \"\"\"Reduce long repeated vowels (e.g., 'aaaa' → 'aa').\"\"\"\n",
    "        optimized_word = []\n",
    "        i = 0\n",
    "        while i < len(roman_word):\n",
    "            match = re.match(r\"([a-zA-Z])\\1{2,}\", roman_word[i:])\n",
    "            if match:\n",
    "                char = match.group(1)\n",
    "                optimized_word.append(char)  # Keep one repetition (aa, ee, etc.)\n",
    "                i += len(match.group(0))\n",
    "            else:\n",
    "                optimized_word.append(roman_word[i])\n",
    "                i += 1\n",
    "        return \"\".join(optimized_word)\n",
    "\n",
    "\n",
    "\n",
    "def generate_variations(word):\n",
    "    normalize_word = handle_repeated_chars(word)\n",
    "\n",
    "    new_words = [normalize_word]\n",
    "\n",
    "    for key, variations in consonant_map.items():\n",
    "        for variation in variations:\n",
    "            if variation in normalize_word and (key not in normalize_word or key in [\"e\"]):\n",
    "                normalize_word = normalize_word.replace(variation, key)\n",
    "    new_words.append(normalize_word)\n",
    "    # print('new_words', new_words)\n",
    "\n",
    "    new_variations = list(new_words)\n",
    "    # print('new_variations', new_variations)\n",
    "    for roman_word in new_words:\n",
    "        tokens = []\n",
    "        i = 0\n",
    "        while i < len(roman_word):\n",
    "            # print('roman_word', roman_word)\n",
    "            if i + 1 < len(roman_word) and roman_word[i:i+2] in variation_map:\n",
    "                if (i + 2 < len(roman_word)) and roman_word[i:i+2] in last_word_check_list:\n",
    "                    if roman_word[i] in variation_map:\n",
    "                        tokens.append(variation_map[roman_word[i]])\n",
    "                    else:\n",
    "                        tokens.append([roman_word[i]])\n",
    "                    i += 1\n",
    "                else:\n",
    "                    tokens.append(variation_map[roman_word[i:i+2]])\n",
    "                    i += 2\n",
    "            elif roman_word[i] in variation_map:\n",
    "                if (i + 2 < len(roman_word)) and roman_word[i] in last_word_check_list:\n",
    "                    tokens.append([roman_word[i]])\n",
    "                else:\n",
    "                    tokens.append(variation_map[roman_word[i]])\n",
    "                i += 1\n",
    "            else:\n",
    "                tokens.append([roman_word[i]])\n",
    "                i += 1\n",
    "            # print('tokens', tokens)\n",
    "\n",
    "        variations = [\"\".join(variant) for variant in itertools.product(*tokens)]\n",
    "        new_variations.extend(variations)\n",
    "\n",
    "    return set(new_variations)\n",
    "\n",
    "# Example usage\n",
    "\n",
    "def generate_devnagri_variations(variant):\n",
    "    latin_variations = generate_variations(variant)\n",
    "    # print('latin_variations', latin_variations)\n",
    "    devanagari_variations = []\n",
    "    print('Romanized variations', list(latin_variations))\n",
    "    for variant in latin_variations:\n",
    "        nepali = transliterate(variant, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
    "        devanagari_variations.append(nepali)\n",
    "    return devanagari_variations\n",
    "\n",
    "\n",
    "variant = \"vayerw\"\n",
    "# variant = \"vahirw\"\n",
    "print('word:', variant)\n",
    "devanagari_variations = generate_devnagri_variations(variant)\n",
    "print('Devanagari variations:', devanagari_variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "PICKLE_FILE = \"dictionary/word_count.pkl\"  # Path to the saved pickle file\n",
    "\n",
    "def load_saved_word_count():\n",
    "    \"\"\"Load and return the word frequency dictionary from the pickle file.\"\"\"\n",
    "    if os.path.exists(PICKLE_FILE):\n",
    "        with open(PICKLE_FILE, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    else:\n",
    "        print(\"No saved word count dictionary found.\")\n",
    "        return {}  # Return an empty dictionary if the file doesn't exist\n",
    "\n",
    "# Usage\n",
    "saved_word_count = load_saved_word_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240683"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(saved_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def rank_variants_by_similarity(variants, nepali_dictionary):\n",
    "    \"\"\"\n",
    "    Rank the generated variants by their similarity to words in the Nepali dictionary using TF-IDF.\n",
    "\n",
    "    :param variants: List of transliterated Nepali variants.\n",
    "    :param nepali_dictionary: List of words in the Nepali dictionary.\n",
    "    :return: List of variants ordered by similarity along with matched dictionary word and similarity score.\n",
    "    \"\"\"\n",
    "    # Ensure both dictionary and variants are lists\n",
    "    nepali_dictionary = list(nepali_dictionary)\n",
    "\n",
    "    # Combine variants and dictionary into a single corpus\n",
    "    corpus = nepali_dictionary + variants\n",
    "\n",
    "    # Compute TF-IDF vectors\n",
    "    # vectorizer = TfidfVectorizer(analyzer='char')\n",
    "    vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(2, 4))\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    # Calculate similarity of each variant to the dictionary words\n",
    "    dictionary_size = len(nepali_dictionary)\n",
    "    variant_vectors = tfidf_matrix[dictionary_size:]\n",
    "    dictionary_vectors = tfidf_matrix[:dictionary_size]\n",
    "\n",
    "    similarities = cosine_similarity(variant_vectors, dictionary_vectors)\n",
    "\n",
    "    # Rank variants by maximum similarity to any dictionary word\n",
    "    ranked_variants = []\n",
    "    for i, variant in enumerate(variants):\n",
    "        max_sim_index = similarities[i].argmax()\n",
    "        matched_word = nepali_dictionary[max_sim_index]\n",
    "        similarity_score = similarities[i, max_sim_index]\n",
    "        ranked_variants.append((variant, matched_word, similarity_score))\n",
    "\n",
    "    ranked_variants.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    return ranked_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Romanized variations ['vayeera', 'vayeerw', 'vaayeera', 'bairw', 'vaayerw', 'baira', 'vaayeerw', 'vaayera', 'vayera', 'baerw', 'vayerw']\n",
      "Devanagari variations: ['वयीर', 'वयीर्व्', 'वायीर', 'बैर्व्', 'वायेर्व्', 'बैर', 'वायीर्व्', 'वायेर', 'वयेर', 'बएर्व्', 'वयेर्व्']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_devnagri_variations(variant):\n",
    "    latin_variations = generate_variations(variant)\n",
    "    devanagari_variations = []\n",
    "    print('Romanized variations', list(latin_variations))\n",
    "    for variant in latin_variations:\n",
    "        nepali = transliterate(variant, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
    "        devanagari_variations.append(nepali)\n",
    "    return devanagari_variations\n",
    "\n",
    "\n",
    "\n",
    "variant = \"vayerw\" # \"choto\"\n",
    "devanagari_variations = generate_devnagri_variations(variant)\n",
    "print('Devanagari variations:', devanagari_variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Matched Words:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('वयेर', 'क्वयेर', np.float64(0.7204668089487367)),\n",
       " ('बैर', 'बैरी', np.float64(0.668193957484916)),\n",
       " ('वायेर', 'पायेर', np.float64(0.6276891236382943)),\n",
       " ('बैर्व्', 'बैर्स', np.float64(0.5863163830206566)),\n",
       " ('वायेर्व्', 'बायेर्न', np.float64(0.54104597002049)),\n",
       " ('वयेर्व्', 'क्वयेर', np.float64(0.49828182714931024)),\n",
       " ('वायीर', 'बनवायीं', np.float64(0.40405570998363677)),\n",
       " ('बएर्व्', 'बए', np.float64(0.34740835004328924)),\n",
       " ('वयीर', 'समन्वयी', np.float64(0.32719733439539744)),\n",
       " ('वायीर्व्', 'बनवायीं', np.float64(0.2950942169246739)),\n",
       " ('वयीर्व्', 'नीर्वाह', np.float64(0.2763839519082517))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEPALI_DICTIONARY= saved_word_count\n",
    "top_matched_words = rank_variants_by_similarity(devanagari_variations, NEPALI_DICTIONARY)\n",
    "\n",
    "print(\"\\nTop 5 Matched Words:\")\n",
    "top_matched_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "from metaphone import doublemetaphone\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"files/words_devnagri_root.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Devanagari</th>\n",
       "      <th>Root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xata</td>\n",
       "      <td>छट</td>\n",
       "      <td>छट</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xatw</td>\n",
       "      <td>छट</td>\n",
       "      <td>छट</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xodyo</td>\n",
       "      <td>छोड्यो</td>\n",
       "      <td>छोड्यो</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xoto</td>\n",
       "      <td>छोटो</td>\n",
       "      <td>छोटो</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sidhai</td>\n",
       "      <td>सिधै</td>\n",
       "      <td>सिधा</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Words Devanagari     Root\n",
       "0    xata         छट       छट\n",
       "1    xatw         छट       छट\n",
       "2   xodyo     छोड्यो   छोड्यो\n",
       "3    xoto       छोटो     छोटो\n",
       "4  sidhai       सिधै     सिधा"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('Devanagari')['Words'].apply(list).reset_index()\n",
    "\n",
    "# Filter to only include entries with more than one word\n",
    "filtered = grouped[grouped['Words'].apply(len) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Devanagari</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>परियो</td>\n",
       "      <td>[pariyo, pareyo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>पर्यो</td>\n",
       "      <td>[paryoo, paryo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>पुरै</td>\n",
       "      <td>[paurai, purae]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>भएर</td>\n",
       "      <td>[vayerw, vaera, vayeraw, bhaera]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>भएर</td>\n",
       "      <td>[vayera, vayeraw, vayara, vayerw, bhayera]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>सिधै</td>\n",
       "      <td>[sidhai, siddai]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Devanagari                                       Words\n",
       "3       परियो                            [pariyo, pareyo]\n",
       "4       पर्यो                             [paryoo, paryo]\n",
       "5        पुरै                             [paurai, purae]\n",
       "7         भएर            [vayerw, vaera, vayeraw, bhaera]\n",
       "16        भएर  [vayera, vayeraw, vayara, vayerw, bhayera]\n",
       "18       सिधै                            [sidhai, siddai]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Multiple mappings found: {('पारियो',): 1, ('पारीयो',): 1}\n",
      "✅ Keeping only the most frequent one: '('पारियो',)' — Adding 1\n",
      "❌ Multiple mappings found: {('पार्यु',): 1, ('पर्यो',): 1}\n",
      "✅ Keeping only the most frequent one: '('पार्यु',)' — Adding 1\n",
      "❌ Multiple mappings found: {('पौराई',): 1, ('पुरै',): 1}\n",
      "✅ Keeping only the most frequent one: '('पौराई',)' — Adding 1\n",
      "❌ Multiple mappings found: {('वयेर',): 1, ('बैरा',): 2, ('भएर',): 1}\n",
      "✅ Keeping only the most frequent one: '('बैरा',)' — Adding 2\n",
      "❌ Multiple mappings found: {('बैरा',): 2, ('वायर',): 1, ('वयेर',): 1, ('भयेर',): 1}\n",
      "✅ Keeping only the most frequent one: '('बैरा',)' — Adding 2\n",
      "❌ Multiple mappings found: {('सिधै',): 1, ('सिद्दै',): 1}\n",
      "✅ Keeping only the most frequent one: '('सिधै',)' — Adding 1\n",
      "accurate: 8 total: 17 percent0.47058823529411764\n"
     ]
    }
   ],
   "source": [
    "# from collections import Counter\n",
    "# total = 0\n",
    "# accurate = 0\n",
    "# not_accurate = 0\n",
    "# NEPALI_DICTIONARY = saved_word_count\n",
    "\n",
    "# for nepali_word, variants in zip(filtered['Devanagari'], filtered['Words']):\n",
    "#     # print(\"nepali_word\", nepali_word, 'variants', variants)\n",
    "#     nepali_variations = []\n",
    "#     for variant in variants:\n",
    "#       total +=1\n",
    "#       latin_variations = generate_variations(variant)\n",
    "#       devanagari_variations = []\n",
    "#       for new_variant in latin_variations:\n",
    "#           nepali = transliterate(new_variant, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
    "#           devanagari_variations.append(nepali)\n",
    "#       top_matched_words = rank_variants_by_similarity(devanagari_variations, NEPALI_DICTIONARY)\n",
    "#       nepali = top_matched_words[0][0] if top_matched_words else None\n",
    "#       nepali_variations.append((nepali,))\n",
    "#     # Count occurrences of each mapped Nepali word\n",
    "#     counter = Counter(nepali_variations)\n",
    "#     most_common_word, count = counter.most_common(1)[0]\n",
    "\n",
    "#     if len(counter) == 1:\n",
    "#         print(f\"✅ All variants map to the same Nepali word: '{most_common_word}' — Adding {count}\")\n",
    "#         accurate += count\n",
    "#     else:\n",
    "#         print(f\"❌ Multiple mappings found: {dict(counter)}\")\n",
    "#         print(f\"✅ Keeping only the most frequent one: '{most_common_word}' — Adding {count}\")\n",
    "#         accurate += count\n",
    "# print(f'accurate: {accurate} total: {total} percent{accurate/total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Mismatch: Variant 'pariyo' → Mapped 'पारियो', Expected ' परियो'\n",
      "🔁 Mismatch: Variant 'pareyo' → Mapped 'पारीयो', Expected ' परियो'\n",
      "🔁 Mismatch: Variant 'paryoo' → Mapped 'पार्यु', Expected ' पर्यो'\n",
      "🔁 Mismatch: Variant 'paryo' → Mapped 'पर्यो', Expected ' पर्यो'\n",
      "🔁 Mismatch: Variant 'paurai' → Mapped 'पौराई', Expected ' पुरै'\n",
      "🔁 Mismatch: Variant 'purae' → Mapped 'पुरै', Expected ' पुरै'\n",
      "🔁 Mismatch: Variant 'vayerw' → Mapped 'वयेर', Expected ' भएर'\n",
      "🔁 Mismatch: Variant 'vaera' → Mapped 'बैरा', Expected ' भएर'\n",
      "🔁 Mismatch: Variant 'vayeraw' → Mapped 'बैरा', Expected ' भएर'\n",
      "🔁 Mismatch: Variant 'bhaera' → Mapped 'भएर', Expected ' भएर'\n",
      "🔁 Mismatch: Variant 'vayera' → Mapped 'बैरा', Expected 'भएर'\n",
      "🔁 Mismatch: Variant 'vayeraw' → Mapped 'बैरा', Expected 'भएर'\n",
      "🔁 Mismatch: Variant 'vayara' → Mapped 'वायर', Expected 'भएर'\n",
      "🔁 Mismatch: Variant 'vayerw' → Mapped 'वयेर', Expected 'भएर'\n",
      "🔁 Mismatch: Variant 'bhayera' → Mapped 'भयेर', Expected 'भएर'\n",
      "🔁 Mismatch: Variant 'siddai' → Mapped 'सिद्दै', Expected 'सिधै'\n",
      "accurate: 8, total: 17, percent: 0.47\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "total = 0\n",
    "accurate = 0\n",
    "not_accurate = 0\n",
    "NEPALI_DICTIONARY = saved_word_count\n",
    "\n",
    "for nepali_word, variants in zip(filtered['Devanagari'], filtered['Words']):\n",
    "    nepali_variations = []\n",
    "    for variant in variants:\n",
    "        total += 1\n",
    "        latin_variations = generate_variations(variant)\n",
    "        devanagari_variations = []\n",
    "        for new_variant in latin_variations:\n",
    "            nepali = transliterate(new_variant, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
    "            devanagari_variations.append(nepali)\n",
    "        top_matched_words = rank_variants_by_similarity(devanagari_variations, NEPALI_DICTIONARY)\n",
    "        nepali = top_matched_words[0][0] if top_matched_words else None\n",
    "        nepali_variations.append((nepali, variant))  # store variant too for debugging\n",
    "\n",
    "    # Find the most common mapped word\n",
    "    mapped_words_only = [x[0] for x in nepali_variations]\n",
    "    counter = Counter(mapped_words_only)\n",
    "    most_common_word, count = counter.most_common(1)[0]\n",
    "\n",
    "    # Now keep only those variants where mapped word == most_common_word\n",
    "    filtered_nepali_variations = [\n",
    "        (mapped_word, variant) for mapped_word, variant in nepali_variations if mapped_word == most_common_word\n",
    "    ]\n",
    "\n",
    "    if len(counter) == 1:\n",
    "        print(f\"✅ All variants map to the same Nepali word: '{most_common_word}' — Adding {count}\")\n",
    "        accurate += count\n",
    "    else:\n",
    "        print(f\"❌ Multiple mappings found: {dict(counter)}\")\n",
    "        print(f\"✅ Keeping only the most frequent one: '{most_common_word}' — Adding {count}\")\n",
    "        accurate += count\n",
    "\n",
    "    # Now check mismatches based on filtered mappings\n",
    "    for mapped_word, variant in nepali_variations:\n",
    "        if mapped_word != nepali_word:\n",
    "            print(f\"🔁 Mismatch: Variant '{variant}' → Mapped '{mapped_word}', Expected '{nepali_word}'\")\n",
    "            not_accurate += 1\n",
    "\n",
    "\n",
    "print(f'accurate: {accurate}, total: {total}, percent: {accurate / total:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Multiple mappings found: {'सिधै': 1, 'सिद्दै': 1}\n",
      "✅ Keeping only the most frequent one: 'सिधै' — Adding 1\n",
      "🔁 Mismatch: Variant 'siddai' → Mapped 'सिद्दै', Expected 'सिधै'\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
